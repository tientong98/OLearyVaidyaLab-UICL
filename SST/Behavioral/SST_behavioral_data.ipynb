{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task Description\n",
    "\n",
    "1 run = 128 trials = 96 Go trials (75%) + 32 Stop trials (25%)\n",
    "\n",
    "32 Stop trials = 8 trials per each staircase X 4 staircases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bayesian Parametric Estimation of Stop-Signal Reaction Time Distributions\n",
    "\n",
    "Dora Matzke, Conor V. Dolan, Gordon D. Logan, Scott D. Brown and Eric–Jan Wagenmakers\n",
    "\n",
    "The integration method assumes that SSRT is constant. SSRTs are\n",
    "estimated from the observed go RT distribution and the P(respond | stop–signal) by finding the point (i.e., SSRT + SSD) at which the integral of the go RT distribution equals the P(respond | stop–signal)\n",
    "\n",
    "the integration method involves __deriving the time point at which the internal response to the stop–signal occurs and subtracting SSD to obtain the SSRT__. \n",
    "\n",
    "__In practice, the following procedure is used: Go RTs are collapsed into a single distribution and are rank ordered. Subsequently, the nth go RT is selected, where n is obtained by multiplying the number of go RTs by the P(respond | stop–signal) at a given SSD. Lastly, the SSD is subtracted to arrive at the SSRT. The integration method yields SSRT estimates for each SSD. As estimated SSRTs tend to decrease with increasing SSD (Logan & Burkell, 1986; Logan & Cowan, 1984), SSRTs at different SSDs are often averaged to yield a summary score for each participant.__\n",
    "\n",
    "The integration method has several drawbacks. It assumes that SSRT is constant, an assumption that is certainly incorrect. Moreover, the integration method requires a relatively large number of observations to produce accurate estimates of average SSRT. Researchers are advised to present participants with at least 900 go trials and 60 stop–signal trials on each of five different SSDs (Band, Van Der Molen, & Logan, 2003).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fictitious Inhibitory Differences: How Skewness and Slowing Distort the Estimation of Stopping Latencies\n",
    "\n",
    "Frederick Verbruggen, Christopher D. Chambers, and Gordon D. Logan 2013\n",
    "\n",
    "SSRT is estimated according to the independent-race model (Logan, 1994; Logan & Cowan, 1984; Verbruggen & Logan, 2009a): Performance in the stop task can be modeled as a race between a go process, which is triggered by the presentation of the go stimulus, and a stop process, which is triggered by the presentation of a stop signal. The stop signal occurs after a variable interval, the stop-signal delay (SSD). If the go process finishes before the stop process (i.e., when RT < (SSRT + SSD)), then response inhibition is unsuccessful and a response is executed; if the stop process finishes before the go process (i.e., when RT > (SSRT + SSD)), then the response is correctly withheld. \n",
    "\n",
    "In the integration method, the point at which the stop process finishes is estimated by __integrating the RT distribution and finding the point at which the integral equals the probability of responding, p(respond|signal), for a specific delay. SSRT is then calculated by subtracting SSD from the finishing time.__\n",
    "\n",
    "__The integration method assumes that the finishing time of the stop process corresponds to the nth RT, with n equal to the number of RTs in the RT distribution multiplied by the overall p(respond|signal) (Logan, 1981); SSRT can then be estimated by subtracting the mean SSD from the nth RT (e.g., Ridderinkhof, Band, & Logan, 1999; Verbrug- gen, Liefooghe, & Vandierendonck, 2004).__\n",
    "\n",
    "For the first set of simulations, we estimated SSRT __over all blocks__ using the mean method (SSRT = mean RT – mean SSD) and __the integration method (SSRT = nth RT – mean SSD)__. For the second and third set, we also __estimated SSRT for each block separately using the integration method and then took the average of these four block estimates.__ Trials with an __RT higher than 2,000 were considered to be missed responses__ (in real experiments, there is always a response deadline around this value). These missed trials were excluded when we estimated SSRT using the mean method; for the integration methods, RT for missed responses was set to 2,000.\n",
    "\n",
    "The integration method fared better in the first set of simulations: There was a trend to underestimate SSRT slightly (approximately 4 ms), but there were no obvious group differences caused by changes in the shape of the RT distribution. This is consistent with a recent reliability analysis that used split-half reliability measures (Congdon et al., 2012). However, the second and third set of simulations showed that the small underestimation bias for the integration method became more pronounced when there is gradual slowing of RTs across blocks. This underestimation bias may explain the previously observed negative correlations between SSRT and response slowing (e.g., Jahfari et al., 2010; Leotti & Wager, 2010). Thus, we have demonstrated that the experiment-wide integra- tion method results in reliable and unbiased estimates unless subjects slow their RT gradually.\n",
    "\n",
    "The second and third set of simulations show that a __block-based version of the integration method is less susceptible to bias from response slowing__. When SSRT was estimated for each block separately (number of no-signal trials per block = 45; number of signal trials per block = 15) and then averaged, we obtained a reliable and unbiased SSRT even when there was substantial response slowing. Additional analyses (Figs. S5–S6 in the Supplemental Material) suggest that approximately 40 to 80 trials are required per block (25% of which are signal trials). If there are fewer trials, the estimates become too noisy; if there are more trials, the underestimation bias starts to emerge. We recommend that there are at least 50 signals in total. Thus, we feel that researchers should estimate SSRT for each block separately when strategic slowing is observed and subjects cannot be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../files/VerbruggenChambersLogan2013.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from numpy import nan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bids_dir = '/Shared/oleary/functional/UICL/BIDS/'\n",
    "txt_dir = '/raid0/homes/crcshare/people/Dan_Oleary/UI_College_Life/fMRI_behav_data'\n",
    "\n",
    "sublist = glob(os.path.join(bids_dir, 'sub-*'))\n",
    "sublist = [lb.split('-')[1] for lb in sublist]\n",
    "runs = ['1','2']\n",
    "\n",
    "# Create blank dataframe\n",
    "\n",
    "finaldata_collector = pd.DataFrame()\n",
    "\n",
    "# Start for loop\n",
    "\n",
    "for sub in sublist:\n",
    "    for run in runs:\n",
    "        txtfile = os.path.join(txt_dir, sub, sub + '_ST_' + run + '.txt')\n",
    "        blffile = os.path.join(txt_dir, sub, sub + '_ST_' + run + '.blf')\n",
    "        \n",
    "        # GETTING SSD INFO\n",
    "        ssd_collector = []\n",
    "        collect = False\n",
    "        with open(txtfile, 'r') as ssd:\n",
    "            for line in ssd:\n",
    "                if line.startswith('Subject'):\n",
    "                    collect=True\n",
    "                if line.startswith('Event Type'):\n",
    "                    collect=False\n",
    "                if collect:\n",
    "                    ssd_collector.append(line)           \n",
    "        ssdlist = [str.strip('\\n').split('\\t') for str in ssd_collector]\n",
    "        headers = ssdlist.pop(0)\n",
    "        # import dataframe in pandas, exclude the first row\n",
    "        ssd_data = pd.DataFrame(ssdlist, columns=headers)\n",
    "        ssd_data = ssd_data.drop([0])\n",
    "        # exclude trials in which respond is faster than SSD\n",
    "        for idx in ssd_data.index:\n",
    "            if ssd_data.loc[idx]['Event Type'] == 'Picture':\n",
    "                if ssd_data.loc[idx+1]['Event Type'] != 'Sound':\n",
    "                    ssd_data.drop(idx, inplace=True) \n",
    "        # for stop trials, get onset time of go stim\n",
    "        stim_onset = ssd_data.loc[(ssd_data['Code'] == 'inhib_go:lt') | (ssd_data['Code'] == 'inhib_go:rt') , 'Time']\n",
    "        # for stop trials, get onset time of stop stim\n",
    "        buzzer_onset = ssd_data.loc[(ssd_data['Code'] == 'inhibit'), 'Time']\n",
    "        # forcing those onsets to be interrger\n",
    "        stim_onset = pd.to_numeric(stim_onset, errors='coerce')\n",
    "        buzzer_onset = pd.to_numeric(buzzer_onset, errors='coerce')\n",
    "        # creating a variable called 'ssd' storing all SSDs, then convert it to ms)\n",
    "        # SSD = Buzzer onset - Arrow onset\n",
    "        ssd = np.subtract(buzzer_onset, stim_onset)\n",
    "        ssd = ssd/10\n",
    "        \n",
    "        # GETTING STAIRCASE INFO\n",
    "\n",
    "        stair_collector = []\n",
    "        collect = False\n",
    "        with open(blffile, 'r') as stair:\n",
    "            for line in stair:\n",
    "                if line.startswith('rest'):\n",
    "                    collect=True\n",
    "                if line.startswith('StaircaseStart:'):\n",
    "                    collect=False\n",
    "                if collect:\n",
    "                    stair_collector.append(line)\n",
    "\n",
    "        stairlist = [str.strip('\\n').split('\\t') for str in stair_collector]\n",
    "\n",
    "        # import dataframe in pandas\n",
    "        stair_data = pd.DataFrame(stairlist)\n",
    "        # dropping all unnecessary rows, so that the dataframe only \n",
    "        # include information regarding the 4 staircases\n",
    "        stair_data = stair_data[stair_data[1].str.contains(\"0|Right|Left\") == False]\n",
    "        # making a variable storing the order in which each staircase was presented in a run\n",
    "        staircase = stair_data[1]\n",
    "        \n",
    "        \n",
    "        # GETTING GO RT \n",
    "\n",
    "        rt_collector = []\n",
    "        collect = False\n",
    "        with open(txtfile, 'r') as rt:\n",
    "            for line in rt:\n",
    "                if line.startswith('Event Type'):\n",
    "                    collect=True\n",
    "                if collect:\n",
    "                    rt_collector.append(line)\n",
    "\n",
    "        rtlist = [str.strip('\\n').split('\\t') for str in rt_collector]\n",
    "        headers = rtlist.pop(0) \n",
    "\n",
    "\n",
    "        # import dataframe in pandas, exclude the first row\n",
    "        rt_data = pd.DataFrame(rtlist, columns=headers)\n",
    "        rt_data = rt_data.drop([0])\n",
    "\n",
    "        # identify go and stop trials\n",
    "        rt_data['Go'] = np.where(rt_data.Code == 'go:rt', 'go',np.where(rt_data.Code == 'go:lt','go', ''))\n",
    "        rt_data['Stop'] = np.where(rt_data.Code == 'inhib_go:rt', 'stop',np.where(rt_data.Code == 'inhib_go:lt','stop', ''))\n",
    "\n",
    "        # Go trials categories: \n",
    "            # correct go (press correct button when there was no buzzer) \n",
    "            # incorrect go (press wrong button when there was no buzzer)\n",
    "            # missed go (did not press button when there was no buzzer)\n",
    "\n",
    "        # Stop trials categories: \n",
    "            # correct stop (suppress pressing button when there was buzzer) \n",
    "            # incorrect stop (press correct button when there was buzzer)\n",
    "            # failed stop (press wrong button when there was buzzer)\n",
    "\n",
    "        rt_data['trial_type'] = np.where((rt_data.Go == 'go') & (rt_data.Type == 'hit'), 'CorGo',\n",
    "                                    np.where((rt_data.Go == 'go') & (rt_data.Type == 'incorrect'), 'IncGo',\n",
    "                                    np.where((rt_data.Go == 'go') & (rt_data.Type == 'miss'), 'MissGo',\n",
    "                                    np.where((rt_data.Stop == 'stop') & (rt_data.Type == 'miss'), 'CorStop',\n",
    "                                    np.where((rt_data.Stop == 'stop') & (rt_data.Type == 'hit'), 'IncStop',\n",
    "                                    np.where((rt_data.Stop == 'stop') & (rt_data.Type == 'incorrect'), 'FailStop',''\n",
    "                                   ))))))\n",
    "\n",
    "        # converting values in the  RT column to numeric then calculate the correct RT (ms) from raw data\n",
    "        rt_data['RT'] = pd.to_numeric(rt_data['RT'])\n",
    "        rt_data['RT'] = (rt_data['RT'] / 10)\n",
    "\n",
    "        # for stop trials only, extract trial type, then stored this as a df named 'stop'\n",
    "        stop = rt_data.loc[(rt_data['Stop'] == 'stop'), 'trial_type']\n",
    "\n",
    "        # for CorGo trials only, extract trial-by-trial RT, then stored this as a df named 'go_rt'\n",
    "        go_rt = rt_data.loc[(rt_data['trial_type'] == 'CorGo'), 'RT']\n",
    "        # calculate mean Go RT of correct go trials\n",
    "        meanGoRT = go_rt.mean()\n",
    "        \n",
    "        # SSRT CALCULATION\n",
    "        \n",
    "        # CALCULATE SSRT STEP 1: making a dataframe named 'stop_trials' that included all information about \n",
    "        # SSDs, stair cases and trial types OF STOP TRIALS ONLY in a run\n",
    "        # dropping row and column index of SSD, stair case, and trial types\n",
    "        ssd.reset_index(drop=True, inplace=True)\n",
    "        ssd.columns = range(ssd.shape[0])\n",
    "        staircase.reset_index(drop=True, inplace=True)\n",
    "        staircase.columns = range(staircase.shape[0])\n",
    "        stop.reset_index(drop=True, inplace=True)\n",
    "        stop.columns = range(stop.shape[0])\n",
    "        # then do concatnation\n",
    "        stop_trials = pd.concat([ssd, staircase, stop], axis=1, ignore_index=True)\n",
    "        stop_trials = stop_trials.dropna()\n",
    "        \n",
    "        # CALCULATE SSRT STEP 2: calculate P(respond | stop–signal) for each SSD\n",
    "        # Step 2A: counting number of incorrect stop for each staircase\n",
    "        n_first_stair_incstop = len (stop_trials[(stop_trials[1].str.contains(\"2|3|4\") == False)  \n",
    "                                                 & (stop_trials[2].str.contains(\"IncStop\") == True)])\n",
    "        n_second_stair_incstop = len (stop_trials[(stop_trials[1].str.contains(\"1|3|4\") == False)  \n",
    "                                                 & (stop_trials[2].str.contains(\"IncStop\") == True)])\n",
    "        n_third_stair_incstop = len (stop_trials[(stop_trials[1].str.contains(\"1|2|4\") == False)  \n",
    "                                                 & (stop_trials[2].str.contains(\"IncStop\") == True)])\n",
    "        n_fourth_stair_incstop = len (stop_trials[(stop_trials[1].str.contains(\"1|2|3\") == False)  \n",
    "                                                 & (stop_trials[2].str.contains(\"IncStop\") == True)])\n",
    "                \n",
    "        # Step 2B: calculate P(respond | stop–signal)\n",
    "        first_stair_p =  n_first_stair_incstop / 8 * 100\n",
    "        second_stair_p =  n_second_stair_incstop / 8 * 100\n",
    "        third_stair_p =  n_third_stair_incstop / 8 * 100\n",
    "        fourth_stair_p =  n_fourth_stair_incstop / 8 * 100\n",
    "        \n",
    "        \n",
    "        # CALCULATE SSRT STEP 2: find the nth RT \n",
    "        GoNRT1 = np.percentile(go_rt, first_stair_p, interpolation = 'midpoint')\n",
    "        GoNRT2 = np.percentile(go_rt, second_stair_p, interpolation = 'midpoint')\n",
    "        GoNRT3 = np.percentile(go_rt, third_stair_p, interpolation = 'midpoint')\n",
    "        GoNRT4 = np.percentile(go_rt, fourth_stair_p, interpolation = 'midpoint')\n",
    "        \n",
    "        # STEP 3: Calculate SSRT\n",
    "        # STEP 3A: Create dataframe of each staircase\n",
    "            # First, creating a df called 'first_stair' that include stop trials of the 1st staircase\n",
    "            # remember that 'stop_trials' is the dataframe that include the information about \n",
    "            # SSD, stair case, stop trial types (CorStop, IncStop, FailStop)\n",
    "        first_stair = stop_trials[(stop_trials[1].str.contains(\"2|3|4\") == False)]\n",
    "        second_stair = stop_trials[(stop_trials[1].str.contains(\"1|3|4\") == False)]\n",
    "        third_stair = stop_trials[(stop_trials[1].str.contains(\"1|2|4\") == False)]\n",
    "        fourth_stair = stop_trials[(stop_trials[1].str.contains(\"1|2|3\") == False)]\n",
    "        \n",
    "        # Then, calculate the mean SSD across all SSDs of one staircase\n",
    "        SSD1 = first_stair[0].mean()\n",
    "        SSD2 = second_stair[0].mean()\n",
    "        SSD3 = third_stair[0].mean()\n",
    "        SSD4 = fourth_stair[0].mean()\n",
    "        \n",
    "        # STEP 3B: SSRT = nth RT - mean SSD \n",
    "        SSRT1 = GoNRT1 - SSD1\n",
    "        SSRT2 = GoNRT2 - SSD2\n",
    "        SSRT3 = GoNRT3 - SSD3\n",
    "        SSRT4 = GoNRT4 - SSD4\n",
    "        \n",
    "        # STEP 4: SSRTs at different SSDs are often averaged to yield a summary score for each participant\n",
    "        meanSSRT = (SSRT1 + SSRT2 + SSRT3 + SSRT4) / 4\n",
    "        meanNGoRT = (GoNRT1 + GoNRT2 + GoNRT3 + GoNRT4) / 4\n",
    "        meanSSD = (SSD1 + SSD2 + SSD3 + SSD4) / 4\n",
    "        \n",
    "        # CALCULATING GO ACCURACY\n",
    "        \n",
    "        # counting the number of correct go trials\n",
    "        N_CorGo = len(rt_data[(rt_data['trial_type'].str.contains(\"CorGo\") == True)])\n",
    "        # counting the number of total go trials\n",
    "        N_Go = 96\n",
    "        # Accuracy Go trials\n",
    "        Accuracy_Go = N_CorGo / N_Go * 100\n",
    "        \n",
    "        # CALCULATING STOP ACCURACY\n",
    "        \n",
    "        # counting the number of correct Stop trials\n",
    "        N_CorStop = len(rt_data[(rt_data['trial_type'].str.contains(\"CorStop\") == True)])\n",
    "        # counting the number of total Stop trials\n",
    "        N_Stop = 32\n",
    "        # Accuracy Stop trials\n",
    "        Accuracy_Stop = N_CorStop / N_Stop * 100\n",
    "        \n",
    "        # CALCULATING STOP ACCURACY FOR EACH STAIR CASE\n",
    "        # then, count the number of CorStop trials of the 1st staircase\n",
    "        n_first_stair_corstop = len (stop_trials[(stop_trials[1].str.contains(\"2|3|4\") == False)  \n",
    "                                                 & (stop_trials[2].str.contains(\"CorStop\") == True)])\n",
    "        Accuracy_Stop_1ststair = n_first_stair_corstop / 8 * 100 \n",
    "        # then, count the number of CorStop trials of the 2nd staircase\n",
    "        n_second_stair_corstop = len (stop_trials[(stop_trials[1].str.contains(\"1|3|4\") == False)  \n",
    "                                                  & (stop_trials[2].str.contains(\"CorStop\") == True)])\n",
    "        Accuracy_Stop_2ndstair = n_second_stair_corstop / 8 * 100 \n",
    "        # then, count the number of CorStop trials of the 3rd staircase\n",
    "        n_third_stair_corstop = len (stop_trials[(stop_trials[1].str.contains(\"1|2|4\") == False)  \n",
    "                                                 & (stop_trials[2].str.contains(\"CorStop\") == True)])\n",
    "        Accuracy_Stop_3rdstair = n_third_stair_corstop / 8 * 100 \n",
    "        # then, count the number of CorStop trials of the 4th staircase\n",
    "        n_fourth_stair_corstop = len (stop_trials[(stop_trials[1].str.contains(\"1|2|3\") == False)  \n",
    "                                                  & (stop_trials[2].str.contains(\"CorStop\") == True)])\n",
    "        Accuracy_Stop_4thstair = n_fourth_stair_corstop / 8 * 100\n",
    "        \n",
    "        \n",
    "        N_IncGo = len(rt_data[(rt_data['trial_type'].str.contains(\"IncGo\") == True)])\n",
    "        Percent_IncGo = N_IncGo / N_Go * 100\n",
    "        N_MissGo = len(rt_data[(rt_data['trial_type'].str.contains(\"MissGo\") == True)])\n",
    "        Percent_MissGo = N_MissGo / N_Go * 100\n",
    "        N_IncStop = len(rt_data[(rt_data['trial_type'].str.contains(\"IncStop\") == True)])\n",
    "        Percent_IncStop = N_IncStop / N_Stop * 100\n",
    "        N_FailStop = len(rt_data[(rt_data['trial_type'].str.contains(\"FailStop\") == True)])\n",
    "        Percent_FailStop = N_FailStop / N_Stop * 100\n",
    "        \n",
    "        #Create a Dictionary of series\n",
    "        d = {'SubID':sub,\n",
    "             'Run':run,\n",
    "             'GoNRT1':GoNRT1,\n",
    "             'GoNRT2':GoNRT2,\n",
    "             'GoNRT3':GoNRT3,\n",
    "             'GoNRT4':GoNRT4,\n",
    "             'meanNGoRT':meanNGoRT,\n",
    "             'SSD1':SSD1,\n",
    "             'SSD2':SSD2,\n",
    "             'SSD3':SSD3,\n",
    "             'SSD4':SSD4,\n",
    "             'meanSSD':meanSSD,\n",
    "             'SSRT1':SSRT1,\n",
    "             'SSRT2':SSRT2,\n",
    "             'SSRT3':SSRT3,\n",
    "             'SSRT4':SSRT4,\n",
    "             'meanSSRT':meanSSRT,\n",
    "             'Accuracy_Go':Accuracy_Go,\n",
    "             'Accuracy_Stop':Accuracy_Stop,\n",
    "             'Accuracy_Stop_1ststair':Accuracy_Stop_1ststair,\n",
    "             'Accuracy_Stop_2ndstair':Accuracy_Stop_2ndstair,\n",
    "             'Accuracy_Stop_3rdstair':Accuracy_Stop_3rdstair,\n",
    "             'Accuracy_Stop_4thstair':Accuracy_Stop_4thstair,\n",
    "             'meanGoRT':meanGoRT,\n",
    "             'Percent_IncGo':Percent_IncGo,\n",
    "             'Percent_MissGo':Percent_MissGo,\n",
    "             'Percent_IncStop':Percent_IncStop,\n",
    "             'Percent_FailStop':Percent_FailStop\n",
    "            }\n",
    "\n",
    "        #Create a DataFrame\n",
    "        finaldata_collector = finaldata_collector.append(d, ignore_index=True)\n",
    "        \n",
    "out_file = os.path.join('/Shared/oleary/functional/UICL/BIDS/code/behav_data', 'SST-Behav-Data-ses1.csv')\n",
    "finaldata_collector.to_csv(out_file, na_rep = 'n/a', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
